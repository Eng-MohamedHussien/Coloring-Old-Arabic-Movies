{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "import keras\n",
    "from keras import backend as k\n",
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization , Conv2D , LeakyReLU,Conv2DTranspose , Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling input and output Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training images\n",
    "train_images = pickle.load(open(\"inputs.p\", \"rb\" ))\n",
    "\n",
    "# Load image labels\n",
    "labels = pickle.load(open(\"outputs.p\", \"rb\" ))\n",
    "\n",
    "# Make into arrays as the neural network wants these\n",
    "#train_images = np.array(train_images)\n",
    "#labels = np.array(labels)\n",
    "\n",
    "augmented_images, augmented_labels=[],[]\n",
    "for image,label in zip(train_images,labels):\n",
    "    augmented_images.append(np.array(image))\n",
    "    augmented_labels.append(np.array(label))\n",
    "    augmented_images.append(np.array(cv2.flip(image,1)))\n",
    "    augmented_labels.append(np.expand_dims(np.array(cv2.flip(label,1)),axis=2))\n",
    "    \n",
    "augmented_images=np.array(augmented_images)\n",
    "augmented_labels=np.array(augmented_labels)\n",
    "\n",
    "# Shuffle images along with their labels, then split into training/validation sets\n",
    "train_images, labels = shuffle(augmented_images, augmented_labels)\n",
    "# Validation set size 10% and remainder for training\n",
    "X_train, X_val, y_train, y_val \n",
    "    = train_test_split(train_images,labels, test_size=0.1)    \n",
    "#setting some parameters\n",
    "batch_size = 1000\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mohamed/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/mohamed/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_1 (Batch (None, 256, 256, 1)       4         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 256, 256, 64)      1088      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 256, 256, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 128, 128, 64)      65600     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 64, 64, 128)       131200    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 32, 32, 256)       524544    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv5 (Conv2D)               (None, 16, 16, 512)       2097664   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv6 (Conv2D)               (None, 8, 8, 512)         4194816   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv7 (Conv2D)               (None, 4, 4, 512)         4194816   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv8 (Conv2D)               (None, 2, 2, 512)         4194816   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "deconv1 (Conv2DTranspose)    (None, 4, 4, 512)         4194816   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "deconv2 (Conv2DTranspose)    (None, 8, 8, 512)         4194816   \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "deconv3 (Conv2DTranspose)    (None, 16, 16, 512)       4194816   \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "deconv4 (Conv2DTranspose)    (None, 32, 32, 256)       2097408   \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "deconv5 (Conv2DTranspose)    (None, 64, 64, 128)       524416    \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "deconv6 (Conv2DTranspose)    (None, 128, 128, 64)      131136    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "deconv7 (Conv2DTranspose)    (None, 256, 256, 64)      65600     \n",
      "_________________________________________________________________\n",
      "last_layer (Conv2D)          (None, 256, 256, 3)       3075      \n",
      "=================================================================\n",
      "Total params: 30,810,631\n",
      "Trainable params: 30,810,629\n",
      "Non-trainable params: 2\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape=(256,256,1)))\n",
    "#encoder part\n",
    "model.add(Conv2D(64,(4,4),padding='same',strides=(1,1),name='conv1'))\n",
    "model.add(LeakyReLU(alpha=0.2))\n",
    "model.add(Conv2D(64,(4,4),padding='same',strides=(2,2),name='conv2'))\n",
    "model.add(LeakyReLU(alpha=0.2))\n",
    "model.add(Conv2D(128,(4,4),padding='same',strides=(2,2),name='conv3'))\n",
    "model.add(LeakyReLU(alpha=0.2))\n",
    "model.add(Conv2D(256,(4,4),padding='same',strides=(2,2),name='conv4'))\n",
    "model.add(LeakyReLU(alpha=0.2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(512,(4,4),padding='same',strides=(2,2),name='conv5'))\n",
    "model.add(LeakyReLU(alpha=0.2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(512,(4,4),padding='same',strides=(2,2),name='conv6'))\n",
    "model.add(LeakyReLU(alpha=0.2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(512,(4,4),padding='same',strides=(2,2),name='conv7'))\n",
    "model.add(LeakyReLU(alpha=0.2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(512,(4,4),padding='same',strides=(2,2),name='conv8'))\n",
    "model.add(LeakyReLU(alpha=0.2))\n",
    "model.add(Dropout(0.2))\n",
    "#decoder part\n",
    "model.add(Conv2DTranspose(512,(4,4),padding='same',strides=(2,2),activation='relu',name='deconv1'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2DTranspose(512,(4,4),padding='same',strides=(2,2),activation='relu',name='deconv2'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2DTranspose(512,(4,4),padding='same',strides=(2,2),activation='relu',name='deconv3'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2DTranspose(256,(4,4),padding='same',strides=(2,2),activation='relu',name='deconv4'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2DTranspose(128,(4,4),padding='same',strides=(2,2),activation='relu',name='deconv5'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2DTranspose(64,(4,4),padding='same',strides=(2,2),activation='relu',name='deconv6'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2DTranspose(64,(4,4),padding='same',strides=(2,2),activation='relu',name='deconv7'))\n",
    "#last layer\n",
    "model.add(Conv2D(3,(4,4),padding='same',strides=(1,1),activation='tanh',name='last_layer'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling model and train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile our model\n",
    "model.compile(loss='mean_squared_error', optimizer='Adam', metrics=['accuracy'])\n",
    "#save our model each epoch\n",
    "ModelCheckpoint(filepath = 'movieColor.h5')\n",
    "# training our model\n",
    "model.fit_generator(ImageDataGenerator().flow(X_train, y_train, batch_size=batch_size),steps_per_epoch = len(X_train)/batch_size,validation_data = ImageDataGenerator().flow(X_val, y_val, batch_size=250) \n",
    "                    ,validation_steps = len(X_val)/250 ,epochs = 10,verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
